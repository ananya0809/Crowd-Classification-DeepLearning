{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minor Project\n",
    "### Crowd Classification using Deep Learning, Computer Vision and Decision Tree\n",
    "### Guide: Dr. Sunil Kumar\n",
    "### Students: Ananya Agrawal (199303010) & Hardik Srivastava (199303069)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Tensorflow inference to generate heatmap of crowd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-20 03:57:36.530766: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-20 03:57:36.538928: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-20 03:57:36.538945: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import sys\n",
    "from pyheatmap.heatmap import HeatMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Model and Weights from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-20 03:57:41.206210: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-20 03:57:41.206316: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-20 03:57:41.206337: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (bigfloppa): /proc/driver/nvidia/version does not exist\n",
      "2022-05-20 03:57:41.206566: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = keras.models.model_from_json(loaded_model_json)\n",
    "\n",
    "model.load_weights(\"weights.h5\")\n",
    "\n",
    "print(\"Loaded model from disk successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up paths of image and other things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = \"/home/hardik/Projects/Minor-Project/new/IMG_233.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and preprocessing input image to correspond to input layer size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(cv2.imread(input_image, 0))\n",
    "img = (img - 127.5) / 128\n",
    "inputs = np.reshape(img, [1, 768, 1024, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inferencing through model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 296ms/step\n"
     ]
    }
   ],
   "source": [
    "outputs = model.predict(inputs)\n",
    "predicted_count = np.sum(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing predicted count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Count: 27.358072\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted Count:\", predicted_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating density numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p_den = np.reshape(outputs, (outputs.shape[1], outputs.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmap Generated to output.png\n"
     ]
    }
   ],
   "source": [
    "den_resized = np.zeros((y_p_den.shape[0] * 4, y_p_den.shape[1] * 4))\n",
    "for i in range(den_resized.shape[0]):\n",
    "    for j in range(den_resized.shape[1]):\n",
    "        den_resized[i][j] = y_p_den[int(i / 4)][int(j / 4)] / 16\n",
    "den = den_resized\n",
    "count = np.sum(den)\n",
    "den = den * 10 / np.max(den)\n",
    "\n",
    "crowd_img = cv2.imread(input_image, 1)\n",
    "\n",
    "data = []\n",
    "pts = []\n",
    "\n",
    "for j in range(len(den)):\n",
    "    for i in range(len(den[0])):\n",
    "        for k in range(int(den[j][i])):\n",
    "            data.append([i + 1, j + 1])\n",
    "            pts.append((i + 1, j + 1))\n",
    "\n",
    "hm = HeatMap(data, base=input_image)\n",
    "hm.heatmap(save_as = 'output.png')\n",
    "print(\"Heatmap Generated to output.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load data and create Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification (Target Label Generation) using Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMG_NUM</th>\n",
       "      <th>SOURCE_DATASET</th>\n",
       "      <th>AB</th>\n",
       "      <th>AC</th>\n",
       "      <th>AD</th>\n",
       "      <th>AE</th>\n",
       "      <th>BC</th>\n",
       "      <th>BD</th>\n",
       "      <th>BE</th>\n",
       "      <th>CD</th>\n",
       "      <th>CE</th>\n",
       "      <th>DE</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>A</td>\n",
       "      <td>226.214500</td>\n",
       "      <td>6.403124</td>\n",
       "      <td>174.287119</td>\n",
       "      <td>12.041595</td>\n",
       "      <td>86.815897</td>\n",
       "      <td>9.219544</td>\n",
       "      <td>6.324555</td>\n",
       "      <td>9.486833</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>8.485281</td>\n",
       "      <td>dense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>A</td>\n",
       "      <td>339.676317</td>\n",
       "      <td>62.801274</td>\n",
       "      <td>152.947703</td>\n",
       "      <td>70.710678</td>\n",
       "      <td>42.059482</td>\n",
       "      <td>57.454330</td>\n",
       "      <td>354.407957</td>\n",
       "      <td>84.504438</td>\n",
       "      <td>49.091751</td>\n",
       "      <td>385.149322</td>\n",
       "      <td>dense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>341</td>\n",
       "      <td>A</td>\n",
       "      <td>71.168813</td>\n",
       "      <td>322.076078</td>\n",
       "      <td>307.483333</td>\n",
       "      <td>52.239832</td>\n",
       "      <td>234.326695</td>\n",
       "      <td>557.288076</td>\n",
       "      <td>306.778422</td>\n",
       "      <td>542.860940</td>\n",
       "      <td>486.864458</td>\n",
       "      <td>43.680659</td>\n",
       "      <td>dense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>378</td>\n",
       "      <td>A</td>\n",
       "      <td>302.828334</td>\n",
       "      <td>21.633308</td>\n",
       "      <td>243.895469</td>\n",
       "      <td>37.483330</td>\n",
       "      <td>550.905618</td>\n",
       "      <td>728.715308</td>\n",
       "      <td>21.095023</td>\n",
       "      <td>294.183616</td>\n",
       "      <td>283.444880</td>\n",
       "      <td>493.852205</td>\n",
       "      <td>dense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>26.172505</td>\n",
       "      <td>41.109610</td>\n",
       "      <td>287.141080</td>\n",
       "      <td>368.989160</td>\n",
       "      <td>29.732137</td>\n",
       "      <td>41.629317</td>\n",
       "      <td>31.622777</td>\n",
       "      <td>40.607881</td>\n",
       "      <td>215.520301</td>\n",
       "      <td>25.495098</td>\n",
       "      <td>dense</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IMG_NUM SOURCE_DATASET          AB          AC          AD          AE  \\\n",
       "0       28              A  226.214500    6.403124  174.287119   12.041595   \n",
       "1       42              A  339.676317   62.801274  152.947703   70.710678   \n",
       "2      341              A   71.168813  322.076078  307.483333   52.239832   \n",
       "3      378              A  302.828334   21.633308  243.895469   37.483330   \n",
       "4       14              A   26.172505   41.109610  287.141080  368.989160   \n",
       "\n",
       "           BC          BD          BE          CD          CE          DE  \\\n",
       "0   86.815897    9.219544    6.324555    9.486833    7.071068    8.485281   \n",
       "1   42.059482   57.454330  354.407957   84.504438   49.091751  385.149322   \n",
       "2  234.326695  557.288076  306.778422  542.860940  486.864458   43.680659   \n",
       "3  550.905618  728.715308   21.095023  294.183616  283.444880  493.852205   \n",
       "4   29.732137   41.629317   31.622777   40.607881  215.520301   25.495098   \n",
       "\n",
       "  TARGET  \n",
       "0  dense  \n",
       "1  dense  \n",
       "2  dense  \n",
       "3  dense  \n",
       "4  dense  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_data = pd.read_csv(\"exported.csv\", index_col=0)\n",
    "cluster_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing X and Y slices of data, where X is our source data and Y contains the Target Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cluster_data.values[:, 2:-1]\n",
    "Y = cluster_data.values[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into Train and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up functions to create decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform training with giniIndex.\n",
    "def train_using_gini(X_train, y_train):\n",
    "    # Creating the classifier object\n",
    "    clf_gini = DecisionTreeClassifier(criterion = \"gini\", random_state = 100, max_depth=None, min_samples_leaf=5)\n",
    "    # Performing training\n",
    "    clf_gini.fit(X_train, y_train)\n",
    "    return clf_gini\n",
    "\n",
    "# Function to make predictions\n",
    "def prediction(X_test, clf_object):  \n",
    "    # Predicton on test with giniIndex\n",
    "    y_pred = clf_object.predict(X_test)\n",
    "    print(\"Predicted values:\")\n",
    "    print(y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_gini = train_using_gini(X, Y)\n",
    "\n",
    "\n",
    "# y_pred_gini = prediction(X_test, clf_gini)\n",
    "# cal_accuracy(y_test, y_pred_gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mat4py import loadmat\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# creates clusters of pts list\n",
    "def make_clusters(pts):\n",
    "    est = KMeans(5)\n",
    "    est.fit(pts)\n",
    "    y_kmeans = est.predict(pts)\n",
    "    # cluster list\n",
    "    cluster_list = [[], [], [], [], []]\n",
    "    for index in range(len(pts)):\n",
    "        cluster_list[y_kmeans[index]].append(pts[index])\n",
    "    return cluster_list\n",
    "\n",
    "# returns dist between 2 points\n",
    "def pt_dist(p1, p2):\n",
    "    xx = p1[0] - p2[0]\n",
    "    yy = p1[1] - p2[1]\n",
    "    return math.sqrt(xx*xx + yy*yy)\n",
    "\n",
    "# returns min dist between cluster 1 and cluster 2\n",
    "def min_dist(c1, c2):\n",
    "    min = 9999999\n",
    "    for p1 in c1:\n",
    "        for p2 in c2:\n",
    "            d = pt_dist(p1, p2)\n",
    "            if min > d:\n",
    "                min = d\n",
    "    return min\n",
    "\n",
    "all_clusters = make_clusters(pts)\n",
    "\n",
    "ab = min_dist(all_clusters[0], all_clusters[1])\n",
    "ac = min_dist(all_clusters[0], all_clusters[2])\n",
    "ad = min_dist(all_clusters[0], all_clusters[3])\n",
    "ae = min_dist(all_clusters[0], all_clusters[4])\n",
    "bc = min_dist(all_clusters[1], all_clusters[2])\n",
    "bd = min_dist(all_clusters[1], all_clusters[3])\n",
    "be = min_dist(all_clusters[1], all_clusters[4])\n",
    "cd = min_dist(all_clusters[2], all_clusters[3])\n",
    "ce = min_dist(all_clusters[2], all_clusters[4])\n",
    "de = min_dist(all_clusters[3], all_clusters[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[563.4696087634186, 81.00617260431454, 301.24076749337894, 1.0, 282.71894170713074, 1.0, 373.5906851087163, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "check_entry = [ab, ac, ad, ae, bc, bd, be, cd, ce, ce]\n",
    "print(check_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values:\n",
      "['dense']\n"
     ]
    }
   ],
   "source": [
    "y_pred_gini = prediction([check_entry], clf_gini)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
